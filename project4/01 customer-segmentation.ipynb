{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer segmentation\n",
    "Data set from kaggle: https://www.kaggle.com/code/fabiendaniel/customer-segmentation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install graphdatascience pandas ipython numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "from graphdatascience import GraphDataScience\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neo4j Connection details\n",
    "DB_ULR = 'neo4j://localhost:7687'\n",
    "DB_USER = 'neo4j'\n",
    "DB_PASS = 'test1234'\n",
    "DB_NAME = 'custseg'\n",
    "gds = GraphDataScience.from_neo4j_driver(DB_ULR, auth=(DB_USER, DB_PASS))\n",
    "gds.version()\n",
    "gds.set_database(DB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.run_cypher(\"create database {dbname} if not exists wait\".format(dbname = DB_NAME), database=\"system\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv file with pandas\n",
    "raw_csv = pd.read_csv('./datasets/data.csv',encoding=\"ISO-8859-1\",\n",
    "                         dtype={'CustomerID': str,'InvoiceID': str})\n",
    "raw_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select customers\n",
    "df_customers = raw_csv[['CustomerID','Country']].drop_duplicates().dropna()\n",
    "df_customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Customer nodes\n",
    "gds.run_cypher('create constraint if not exists for (n:Customer) require (n.id) is node key')\n",
    "create_customer_res = gds.run_cypher('''\n",
    "    unwind $data as row\n",
    "    merge (n:Customer{id: row.CustomerID})\n",
    "        set n.country = row.Country\n",
    "    return count(*) as custmers_created\n",
    "''', params = {'data': df_customers.to_dict('records')})\n",
    "create_customer_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select products\n",
    "df_products = raw_csv[['StockCode','Description']].drop_duplicates().dropna()\n",
    "df_products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Product nodes\n",
    "gds.run_cypher('create constraint if not exists for (n:Product) require (n.id) is node key')\n",
    "create_product_res = gds.run_cypher('''\n",
    "    unwind $data as row\n",
    "    merge (n:Product{id: row.StockCode})\n",
    "        set n.description = row.Description\n",
    "    return count(*) as products_created\n",
    "''', params = {'data': df_products.to_dict('records')})\n",
    "create_product_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select invoice data\n",
    "df_invoices = raw_csv[['InvoiceNo', 'InvoiceDate']].drop_duplicates().dropna()\n",
    "df_invoices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Invoice nodes\n",
    "gds.run_cypher('create constraint if not exists for (n:Invoice) require (n.id) is node key')\n",
    "create_invoice_res = gds.run_cypher('''\n",
    "    unwind $data as row\n",
    "    with row,  apoc.date.parse(row.InvoiceDate, 'ms', 'dd/MM/yyyy HH:mm') as ms\n",
    "    merge (n:Invoice{id: row.InvoiceNo})\n",
    "        set n.invoice_date = datetime( { epochmillis: ms } )\n",
    "    return count(*) as invoices_created\n",
    "''', params = {'data': df_invoices.to_dict('records')})\n",
    "create_invoice_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data for cust - invoice relationship\n",
    "df_billed_to = raw_csv[['CustomerID','InvoiceNo']].drop_duplicates().dropna()\n",
    "df_billed_to.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create billed_to relationship\n",
    "create_bill_to_res = gds.run_cypher('''\n",
    "    unwind $data as row\n",
    "    match (i:Invoice{id: row.InvoiceNo}), (c:Customer{id: row.CustomerID})\n",
    "    merge (i)-[:billed_to]->(c)\n",
    "    return count(*) as bill_to_rels_created\n",
    "''', params = {'data': df_billed_to.to_dict('records')})\n",
    "create_bill_to_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data for invoice - product relationship\n",
    "df_line_item = raw_csv[['InvoiceNo','StockCode','Quantity','UnitPrice']].drop_duplicates().dropna()\n",
    "\n",
    "# We want to store prices in cents so we can represent them as \n",
    "# integer values to avoid rounding errors later on\n",
    "df_line_item['UnitPrice'] = df_line_item['UnitPrice'] * 100 \n",
    "\n",
    "df_line_item.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create line_item relationship\n",
    "create_line_item_res = gds.run_cypher('''\n",
    "    unwind $data as row\n",
    "    match (i:Invoice{id: row.InvoiceNo}), (p:Product{id: row.StockCode})\n",
    "    merge (p)-[li:line_item]->(i)\n",
    "        set li.qty = toInteger(row.Quantity),\n",
    "            li.price = toInteger(row.UnitPrice)\n",
    "    return count(*) as line_item_rels_created\n",
    "''', params = {'data': df_line_item.to_dict('records')})\n",
    "create_line_item_res.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph model so far\n",
    "![](./images/graph_model.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic data exploration\n",
    "Let's just get some picture of our graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag cancelled orders (invoice number starts with C)\n",
    "cancellations = gds.run_cypher('''\n",
    "    call {\n",
    "        // reset just in case we change the logic/rerun\n",
    "        match (i:CancelledOrder)\n",
    "        set i:Invoice remove i:CancelledOrder\n",
    "    }\n",
    "    match (i:Invoice)\n",
    "    where i.id starts with 'C'\n",
    "    set i:CancelledOrder remove i:Invoice\n",
    "    return count(*) as number_of_cancelled_orders\n",
    "''')\n",
    "cancellations.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic product analysis\n",
    "Why start with products? If we don't understand the products we have no domain knowledge when we start looking at customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product sales\n",
    "df_customerinvoices = gds.run_cypher('''\n",
    "    match (p:Product)\n",
    "    return p.id as productId, count { (p)-[:line_item]->(:Invoice) } as number_of_times_ordered\n",
    "''')\n",
    "df_customerinvoices.hist('number_of_times_ordered')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**note**: We should look out for product that are only ordered once or twice (may not be of interest), we shoul also investigate products that are ordereed a lot (might be an invoice fee or something else that stands out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First sold, last sold dates (yea we are going to assume some products are no longer sold, it may be \n",
    "# relevant to know both for customer segmentation but also for recommendations)\n",
    "gds.run_cypher('''\n",
    "    match (p:Product)-[:line_item]->(i:Invoice)\n",
    "    with p, min(i.invoice_date) as first_invoice_date, max(i.invoice_date) as last_invoice_date\n",
    "    set p.first_sold = first_invoice_date,\n",
    "        p.last_sold = last_invoice_date  \n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just assume that products that have not been invoiced the past 5 quarters are no longer sold\n",
    "# Why 5? Some products may be seasonal\n",
    "discontiued_products = gds.run_cypher('''\n",
    "    call { \n",
    "        // reset just in case we change the cutoff\n",
    "        match (d:DiscontinuedProduct)\n",
    "        set d:Product remove d:DiscontinuedProduct \n",
    "    }\n",
    "    match (p:Product)\n",
    "    with max(p.last_sold)  - duration({days:365+90})  as for_sale_cutoff_date\n",
    "    match (p:Product) where p.last_sold < for_sale_cutoff_date\n",
    "        set p:DiscontinuedProduct remove p:Product\n",
    "    return count(*) as number_of_discontiued_products \n",
    "''')\n",
    "discontiued_products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top products (still in sales)\n",
    "gds.run_cypher('''\n",
    "    match (p:Product)\n",
    "    return p.id as productId, \n",
    "        p.description as description, \n",
    "        count { (p)-[:line_item]->() } as number_of_times_ordered \n",
    "    order by number_of_times_ordered desc limit 25\n",
    "''').head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product \"damaged\" stands out, what others are there\n",
    "gds.run_cypher('''\n",
    "    match (p:Product)-[li:line_item]->()\n",
    "    with p, count(distinct(li.price)) as numberOfPrices\n",
    "    where numberOfPrices>1\n",
    "    match  (p)-[li:line_item]->()\n",
    "    return p.id as productId, \n",
    "        collect(li.price) as prices,\n",
    "        p.description as description \n",
    "    order by productId desc limit 25\n",
    "''').head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's treat a few of these as misc fees\n",
    "misc_products = gds.run_cypher('''\n",
    "    call { \n",
    "        // reset just in case we the logic\n",
    "        match (d:AdminCharge)\n",
    "        set d:Product remove d:AdminCharge \n",
    "    }\n",
    "    match (p:Product)\n",
    "    where p.id in $admin_products\n",
    "        set p:AdminCharge remove p:Product\n",
    "    return count(*) as number_of_admin_charges\n",
    "''', params = { 'admin_products': ['POST', 'D', 'C2', 'M', 'BANK CHARGES', 'PADS', 'DOT', 'S', 'DCGS0069','DCGS0003','AMAZONFEE','CRUK','84879','22423'] })\n",
    "misc_products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Products mainly not in uppercase\n",
    "gds.run_cypher('''\n",
    "    match (p:Product)\n",
    "    where apoc.text.distance(p.description, toUpper(p.description)) > 5\n",
    "    return \n",
    "        p.description as description,\n",
    "        count(*) as freq\n",
    "        order by freq desc\n",
    "    '''\n",
    ").head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a few products to uppercase\n",
    "gds.run_cypher('''\n",
    "    match (p:Product)\n",
    "    where p.description in $products\n",
    "    set p.description = toUpper(p.description)\n",
    "    ''', \n",
    "    params = { 'products': [\n",
    "        'Dr. Jam\\'s Arouzer Stress Ball', \n",
    "        'USB Office Mirror Ball',\n",
    "        'FLOWERS HANDBAG blue and orange'\n",
    "    ] }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now re-lable prducts not in uppercase\n",
    "gds.run_cypher('''\n",
    "    match (p:Product)\n",
    "    where apoc.text.distance(p.description, toUpper(p.description)) > 5\n",
    "    set p:AdminCharge remove p:Product\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And re-lable some other trash\n",
    "gds.run_cypher('''\n",
    "    match (p:Product)\n",
    "    where p.description in $products\n",
    "    set p:AdminCharge remove p:Product\n",
    "    ''',\n",
    "    params = { 'products': [\n",
    "        'check',\n",
    "        '?',\n",
    "        'found',\n",
    "        '??',\n",
    "        'Amazon',\n",
    "        'Found',\n",
    "        'ebay',\n",
    "        'CHECK',\n",
    "        'AMAZON',\n",
    "        'test'\n",
    "    ] }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check stats\n",
    "gds.run_cypher('''\n",
    "    match (n)\n",
    "    return labels(n), count(*)\n",
    "    '''\n",
    ").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-visit Product sales after cleanup\n",
    "df_customerinvoices = gds.run_cypher('''\n",
    "    match (p:Product)\n",
    "    return p.id as productId, count { (p)-[:line_item]->(:Invoice) } as number_of_times_ordered\n",
    "''')\n",
    "df_customerinvoices.hist('number_of_times_ordered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-label products that are frequently sold\n",
    "gds.run_cypher('''\n",
    "    match (p:Product)\n",
    "    with p, count { (p)-[:line_item]->(:Invoice) } as number_of_times_ordered\n",
    "    where number_of_times_ordered > 250\n",
    "    set p:FrequentProduct remove p:Product\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-label products that are in-frequently sold\n",
    "gds.run_cypher('''\n",
    "    match (p:Product)\n",
    "    with p, count { (p)-[:line_item]->(:Invoice) } as number_of_times_ordered\n",
    "    where number_of_times_ordered < 2\n",
    "    set p:InFrequentProduct remove p:Product\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze invoices\n",
    "df_invoice_products = gds.run_cypher('''\n",
    "    match (i:Invoice)\n",
    "    return i.id as invoice_id, count { (:Product)-[:line_item]->(i) } as number_of_line_items\n",
    "''')\n",
    "df_invoice_products.hist('number_of_line_items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-label invoices with many line items\n",
    "gds.run_cypher('''\n",
    "    match (i:Invoice)\n",
    "    with i, count { (:Product)-[:line_item]->(i) } as number_of_line_items\n",
    "    where number_of_line_items > 25\n",
    "    set i:BulkInvoice remove i:Invoice\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at words used in product description\n",
    "gds.run_cypher('''\n",
    "    match (p:Product)\n",
    "    where exists { (p)-[:line_item]->(:Invoice) }\n",
    "    with split(trim(p.description),' ') as terms\n",
    "    unwind terms as term\n",
    "    with term where term <> ''\n",
    "    return term, count(*) as freq\n",
    "    order by freq desc limit 100\n",
    "''').head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique terms\n",
    "gds.run_cypher('create constraint if not exists for (n:Term) require (n.id) is node key')\n",
    "gds.run_cypher('''\n",
    "    match (p:Product)\n",
    "    where exists { (p)-[:line_item]->(:Invoice) }\n",
    "    with split(trim(p.description),' ') as terms\n",
    "    unwind terms as term\n",
    "    with distinct term where term <> ''\n",
    "    merge (:Term{id:term})\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate product with term\n",
    "gds.run_cypher('''\n",
    "    match (p:Product)\n",
    "    where exists { (p)-[:line_item]->(:Invoice) }\n",
    "    with p, split(trim(p.description),' ') as terms\n",
    "    match (t:Term) where t.id in terms\n",
    "    with t,p\n",
    "    merge (p)-[:described_by]->(t)\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1, stats = gds.graph.project('g1',['Product','Term'],{'described_by': {'orientation': 'REVERSE'}})\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.nodeSimilarity.stats(G1, \n",
    "    similarityMetric = 'OVERLAP', \n",
    "    similarityCutoff = 0.6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.nodeSimilarity.write(G1, \n",
    "    similarityMetric = 'OVERLAP', \n",
    "    similarityCutoff = 0.6, \n",
    "    writeRelationshipType = 'narrower_than', \n",
    "    writeProperty = 'similarity'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Touch-up: Remove symmetric narrower_than relationships\n",
    "df = gds.run_cypher(\n",
    "    \"\"\"\n",
    "    MATCH (p1:Term)-[r:narrower_than]->(p2:Term)\n",
    "    WHERE (p2)-[:narrower_than]->(p1)\n",
    "    DELETE r\n",
    "    RETURN count(*) as relationships_deleted\n",
    "    \"\"\"\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Touch-up: Make narrower_than point towards the node with the bigger set\n",
    "df = gds.run_cypher(\n",
    "    \"\"\"\n",
    "    MATCH (p1:Term)-[r:narrower_than]->(p2:Term)\n",
    "    WHERE count{ (p1)-[:line_item]->(:Invoice) } > count{ (s2)-[:line_item]->(:Invoice) }\n",
    "    CREATE (s2)-[:narrower_than{similarity: r.similarity}]->(s1)\n",
    "    DELETE r\n",
    "    RETURN count(*) as relationships_reversed\n",
    "    \"\"\"\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2, stats = gds.graph.project('g2',['Term'],['narrower_than'])\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.louvain.stats(G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.louvain.write(G2,writeProperty='community')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.run_cypher('create index if not exists for (n:Term) on (n.community)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product_communities = gds.run_cypher('''\n",
    "    match (t:Term)<-[:described_by]-(p:Product)\n",
    "    return t.community as community, count(distinct p) as number_of_products\n",
    "''')\n",
    "df_product_communities.hist('number_of_products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_community_size = gds.run_cypher('''\n",
    "    match (t:Term)<-[:described_by]-(p:Product)\n",
    "    with t.community as community, count(distinct p) as number_of_products\n",
    "    return number_of_products, count(*) as number_of_communities\n",
    "''')\n",
    "df_community_size.hist('number_of_communities')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic analysis of customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of invoices per customer\n",
    "df_customerinvoices = gds.run_cypher('''\n",
    "    match (c:Customer)\n",
    "    return c.id as custId, count { (c)<-[:billed_to]-() } as number_of_invoices\n",
    "''')\n",
    "df_customerinvoices.hist('number_of_invoices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check amount per customer\n",
    "df_customer_amount = gds.run_cypher('''\n",
    "    match (c:Customer)<-[:billed_to]-(:Invoice)<-[li:line_item]-()\n",
    "    return c.id as custId, sum(li.price*li.qty) as customer_amount\n",
    "''')\n",
    "df_customer_amount.hist('customer_amount')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**note**: We may want to segment customer based on number of invoices, like B2B vs B2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set first and last invoice date on customer nodes\n",
    "gds.run_cypher('''\n",
    "    match (c:Customer)<-[:billed_to]-(i:Invoice)\n",
    "    with c, min(i.invoice_date) as first_invoice_date, max(i.invoice_date) as last_invoice_date\n",
    "    set c.first_invoice_date = first_invoice_date,\n",
    "        c.last_invoice_date = last_invoice_date  \n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the max last_invoice_date\n",
    "max_last_invoice = gds.run_cypher('''\n",
    "    match (c:Customer)\n",
    "    return max(c.last_invoice_date) as max_last_invoice_date\n",
    "''')\n",
    "max_last_invoice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just assume that customers that have not been invoiced the past quarter are churned \n",
    "curned_customers = gds.run_cypher('''\n",
    "    call {\n",
    "        // reset just in case we change the cutoff\n",
    "        match (c:ChurnedCustomer)\n",
    "        set c:Customer remove c:ChurnedCustomer\n",
    "    }\n",
    "    match (c:Customer)\n",
    "    with max(c.last_invoice_date)  - duration({days:90})  as churn_cutoff_date\n",
    "    match (c:Customer) where c.last_invoice_date < churn_cutoff_date\n",
    "        set c:ChurnedCustomer remove c:Customer\n",
    "    return count(*) as number_of_churned_customers \n",
    "''')\n",
    "curned_customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customers by revenue (also includes admin charges)\n",
    "df_customer_order_value = gds.run_cypher('''\n",
    "    match (c:Customer)<-[:billed_to]-(:Invoice)<-[li:line_item]-()\n",
    "    return c.id as customerId,\n",
    "       sum(li.qty * li.price) as total_order_value\n",
    "\n",
    "''')\n",
    "df_customer_order_value.hist('total_order_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hmm, scary close to 0, do we also have customers with a total amount that is negative\n",
    "data = gds.run_cypher('''\n",
    "    match (c:Customer)<-[:billed_to]-(:Invoice)<-[li:line_item]-(p)\n",
    "    with c.id as customerId, sum(li.qty * li.price) as total_order_value\n",
    "    where total_order_value<0\n",
    "    with collect(customerId) as custIds\n",
    "    match (c:Customer)<-[:billed_to]-()<-[li:line_item]-(p:Product)\n",
    "    where c.id in custIds\n",
    "    return c.id as customerId, li.qty as qty, li.price as price, p.id as productId, p.description as product, li.qty*li.price as value\n",
    "    limit 100\n",
    "''')\n",
    "data.head(100)\n",
    "# Remark: It is important that we only go through Invoice nodes as we also have Cancelled invoices (assuming they were never sent/paid)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-factor the graph model \n",
    "Adding customer invoice history as a linked list (or \"customer journey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make \"customer journey\"\n",
    "gds.run_cypher('''\n",
    "    match (c:Customer)<-[:billed_to]-(i:Invoice|CancelledOrder)\n",
    "    with c, i order by i.invoice_date asc\n",
    "    with c, collect(i) as history\n",
    "    CALL apoc.nodes.link(history, \"next\")\n",
    "    WITH c, history[0] as head, history[-1] as tail\n",
    "    CREATE (c)-[:first]->(head)\n",
    "    CREATE (c)-[:last]->(tail)\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collaborative filtering: Other customers who bought this item bought that item later\n",
    "gds.run_cypher('''\n",
    "    match (p:Product{description:\"ALARM CLOCK BAKELIKE PINK\"})-[:line_item]->(i1:Invoice)-[:next]->(i2:Invoice)<-[:line_item]-(nextProduct:Product)\n",
    "    where p<>nextProduct\n",
    "    with p, nextProduct, count(*) as freq\n",
    "    order by freq desc limit 10\n",
    "    return p.id as givenProductId, p.description as givenPruduct,\n",
    "        nextProduct.id as nextProductId, nextProduct.description as nextProduct,\n",
    "        freq\n",
    "''').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Collaborative filtering: Other customers who bought this item bought that item at the same time\n",
    "gds.run_cypher('''\n",
    "    match (p:Product{description:\"ALARM CLOCK BAKELIKE PINK\"})-[:line_item]->(i1:Invoice)<-[:line_item]-(otherProduct:Product)\n",
    "    where p<>otherProduct\n",
    "    with p, otherProduct, count(*) as freq\n",
    "    order by freq desc limit 10\n",
    "    return p.id as givenProductId, p.description as givenPruduct,\n",
    "        otherProduct.id as otherProductId, otherProduct.description as otherProduct,\n",
    "        freq\n",
    "''').head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('notebooks')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c68434ca16130d73e64183f54aeda16ecffce872c062f16976fd0d983519d848"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
